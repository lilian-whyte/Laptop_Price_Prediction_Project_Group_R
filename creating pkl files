import pandas as pd
import pickle
import re
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
import numpy as np

# --- 1. Load your original data from Google Drive (or local path) ---
# This part is done ONCE, offline.
share_link = "https://drive.google.com/file/d/1POVnnp6fBP97E-bCev1s-BnPqMENGzv8/view?usp=drive_link"
file_id = share_link.split('/')[-2]
url = f"https://drive.google.com/uc?export=download&id={file_id}"
df_original = pd.read_csv(url, encoding='latin-1')

# --- 2. Perform all feature engineering and cleaning ---
# ... (all your original feature engineering functions from the notebook) ...
def extract_screen_type(resolution_str):
    types = []
    if 'IPS Panel' in resolution_str:
        types.append('IPS Panel')
    if 'Full HD' in resolution_str:
        types.append('Full HD')
    if 'Retina Display' in resolution_str:
        types.append('Retina Display')
    if 'Touchscreen' in resolution_str:
        types.append('Touchscreen')
    return ', '.join(types) if types else 'Other'

def extract_cpu_brand(cpu_string):
    return cpu_string.split()[0]

def extract_processing_level(cpu_string):
    patterns = [r'Core i[357]', r'Celeron', r'Pentium', r'AMD']
    for pattern in patterns:
        match = re.search(pattern, cpu_string)
        if match:
            return match.group(0)
    return 'Other'

def extract_cpu_details(cpu_string):
    parts = cpu_string.split()
    if len(parts) > 2:
        return ' '.join(parts[2:])
    elif len(parts) > 1:
        return ' '.join(parts[1:])
    return ''

def extract_memory_value(memory_str):
    match = re.search(r'(\d+)(GB|TB)', memory_str)
    if match:
        value = int(match.group(1))
        unit = match.group(2)
        if unit == 'TB':
            value *= 1024
        return value
    return 0

def extract_memory_type(memory_str):
    types = []
    if 'SSD' in memory_str:
        types.append('SSD')
    if 'HDD' in memory_str:
        types.append('HDD')
    if 'Flash Storage' in memory_str:
        types.append('Flash Storage')
    if 'Hybrid' in memory_str:
        types.append('Hybrid')
    return ', '.join(types) if types else 'Other'

def extract_gpu_company(gpu_string):
    return gpu_string.split()[0]

def extract_gpu_type(gpu_string):
    parts = gpu_string.split()
    if len(parts) > 1:
        return ' '.join(parts[1:])
    return ''
# Apply feature engineering
df_original['Screen_Type'] = df_original['ScreenResolution'].apply(extract_screen_type)
df_original['CPU_Brand'] = df_original['Cpu'].apply(extract_cpu_brand)
df_original['Processing_Level'] = df_original['Cpu'].apply(extract_processing_level)
df_original['CPU_Details'] = df_original['Cpu'].apply(extract_cpu_details)
df_original['Memory_Value'] = df_original['Memory'].apply(extract_memory_value)
df_original['Memory_Type'] = df_original['Memory'].apply(extract_memory_type)
df_original['GPU_Company'] = df_original['Gpu'].apply(extract_gpu_company)
df_original['GPU_Type'] = df_original['Gpu'].apply(extract_gpu_type)
df_original['Weight'] = df_original['Weight'].str.replace('kg', '').astype(float)
df_original['Ram'] = df_original['Ram'].str.replace('GB', '').astype(int)

# Target variable transformation
df_original['Price_log'] = np.log(df_original['Price_euros'])

# --- 3. Fit Label Encoders and save preprocessor info ---
label_encoders = {}
categorical_options = {}
numerical_ranges = {}
categorical_cols = ['Company', 'TypeName', 'Screen_Type', 'CPU_Brand', 'Processing_Level', 'CPU_Details', 'Memory_Type', 'GPU_Company', 'GPU_Type', 'OpSys']
for col in categorical_cols:
    le = LabelEncoder()
    le.fit(df_original[col])
    label_encoders[col] = le
    categorical_options[col] = sorted(le.classes_)

# Create numerical ranges dictionary
numerical_cols = ['Inches', 'Ram', 'Weight', 'Memory_Value']
for col in numerical_cols:
    numerical_ranges[col] = {
        'min': float(df_original[col].min()),
        'max': float(df_original[col].max()),
        'mean': float(df_original[col].mean())
    }
    
# Encode the original dataframe for training
df_processed = df_original.copy()
for col, le in label_encoders.items():
    df_processed[col + '_Encoded'] = le.transform(df_processed[col])

# Define features and target
selected_features_encoded = [
    'Inches', 'Ram', 'Weight', 'Memory_Value',
    'Company_Encoded', 'TypeName_Encoded', 'Screen_Type_Encoded',
    'CPU_Brand_Encoded', 'Processing_Level_Encoded', 'CPU_Details_Encoded',
    'Memory_Type_Encoded', 'GPU_Company_Encoded', 'GPU_Type_Encoded', 'OpSys_Encoded'
]
X = df_processed[selected_features_encoded]
y = df_processed['Price_log']

# --- 4. Train the model ---
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X, y)

# --- 5. Save the model and preprocessor ---
preprocessor = {
    'label_encoders': label_encoders,
    'categorical_options': categorical_options,
    'numerical_ranges': numerical_ranges,
    'selected_features_encoded': selected_features_encoded
}

with open('laptop_price_model.pkl', 'wb') as f:
    pickle.dump(model, f)

with open('laptop_preprocessor.pkl', 'wb') as f:
    pickle.dump(preprocessor, f)

print("Model and preprocessor files have been created successfully.")
